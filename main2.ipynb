{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"Dataset\\Train\"\n",
    "validation_dir = r\"Dataset\\Validation\"\n",
    "test_dir = r\"Dataset\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140002 images belonging to 2 classes.\n",
      "Found 39428 images belonging to 2 classes.\n",
      "Found 10905 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfake_classifier(image_size):\n",
    "    input_img = Input(shape=(image_size[0], image_size[1], 3))\n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "    flat = Flatten()(encoded)\n",
    "    dense = Dense(128, activation=\"relu\")(flat)\n",
    "    output = Dense(1, activation=\"sigmoid\")(\n",
    "        dense\n",
    "    )\n",
    "    classifier = Model(input_img, output)\n",
    "    classifier.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"Precision\", \"Recall\"],\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4376/4376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2156s\u001b[0m 492ms/step - Precision: 0.7814 - Recall: 0.8076 - accuracy: 0.7906 - loss: 0.4259 - val_Precision: 0.8695 - val_Recall: 0.9105 - val_accuracy: 0.8865 - val_loss: 0.2648\n",
      "Epoch 2/5\n",
      "\u001b[1m4376/4376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2158s\u001b[0m 493ms/step - Precision: 0.9236 - Recall: 0.9398 - accuracy: 0.9310 - loss: 0.1689 - val_Precision: 0.9007 - val_Recall: 0.9170 - val_accuracy: 0.9076 - val_loss: 0.2232\n",
      "Epoch 3/5\n",
      "\u001b[1m4376/4376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2173s\u001b[0m 497ms/step - Precision: 0.9509 - Recall: 0.9640 - accuracy: 0.9570 - loss: 0.1068 - val_Precision: 0.9135 - val_Recall: 0.9216 - val_accuracy: 0.9168 - val_loss: 0.2146\n",
      "Epoch 4/5\n",
      "\u001b[1m4376/4376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2155s\u001b[0m 492ms/step - Precision: 0.9686 - Recall: 0.9770 - accuracy: 0.9728 - loss: 0.0687 - val_Precision: 0.8994 - val_Recall: 0.9490 - val_accuracy: 0.9211 - val_loss: 0.2426\n",
      "Epoch 5/5\n",
      "\u001b[1m4376/4376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2171s\u001b[0m 496ms/step - Precision: 0.9794 - Recall: 0.9857 - accuracy: 0.9825 - loss: 0.0446 - val_Precision: 0.8654 - val_Recall: 0.9578 - val_accuracy: 0.9041 - val_loss: 0.3505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19dbe768ce0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = deepfake_classifier(image_size)\n",
    "classifier.fit(train_generator, epochs=5, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 112ms/step - Precision: 0.8241 - Recall: 0.8778 - accuracy: 0.8477 - loss: 0.5329\n",
      "Precision:  0.5414142608642578\n",
      "Recall:  0.8268733620643616\n",
      "Accuracy:  0.8867540955543518\n"
     ]
    }
   ],
   "source": [
    "precision, recall, accuracy, loss = classifier.evaluate(test_generator)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"deepfake_autoencoder.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"deepfake_autoencoder.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras2sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn2pmml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sklearn2pmml\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras2sklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      4\u001b[0m estimator \u001b[38;5;241m=\u001b[39m KerasClassifier(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m      6\u001b[0m sklearn2pmml(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepfake_autoencoder.pmml\u001b[39m\u001b[38;5;124m\"\u001b[39m, with_repr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras2sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "from keras2sklearn import KerasClassifier\n",
    "\n",
    "estimator = KerasClassifier(model=model)\n",
    "\n",
    "sklearn2pmml(model, \"deepfake_autoencoder.pmml\", with_repr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, image_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "def predict_image(model, image_path, image_size):\n",
    "    input_image = preprocess_image(image_path, image_size)\n",
    "    prediction = model.predict(input_image)\n",
    "    if prediction[0][0] >= 0.9:\n",
    "        return \"Real\", prediction[0][0]\n",
    "    else:\n",
    "        return \"Deep Fake\", prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Real', 0.95745814)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(model, \"WhatsApp Image 2024-04-13 at 08.59.03_e36450ad.jpg\", (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
